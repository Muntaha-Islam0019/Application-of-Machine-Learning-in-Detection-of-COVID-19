{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:/Study Materials/Practical Materials/Thesis Files/Thesis/data/train\"\n",
    "test_dir = \"D:/Study Materials/Practical Materials/Thesis Files/Thesis/data/train\"\n",
    "val_dir = \"D:/Study Materials/Practical Materials/Thesis Files/Thesis/data/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For VGG16\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For InceptionV3\n",
    "from tensorflow.python.keras.applications.inception_v3 import InceptionV3 \n",
    "from tensorflow.python.keras.applications.inception_v3  import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ResNet50\n",
    "from tensorflow.python.keras.applications.resnet import ResNet50\n",
    "from tensorflow.python.keras.applications.resnet import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Explanable AI\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nOkK9XQafDFM"
   },
   "outputs": [],
   "source": [
    "def transferLayer(model, layer):\n",
    "    conv_model = Model(inputs=model.input, outputs=layer.output)\n",
    "    # Start a new Keras Sequential model\n",
    "    new_model = Sequential()\n",
    "\n",
    "    # Add the convolutional part of the VGG16 model from above\n",
    "    new_model.add(conv_model)\n",
    "\n",
    "    # Flatten the output of the VGG16 model because it is from a convolutional layer\n",
    "    new_model.add(Flatten())\n",
    "\n",
    "    # Add a dense (aka. fully-connected) layer\n",
    "    # This is for combining features that the VGG16 model has recognized in the image\n",
    "    new_model.add(Dropout(0.5))\n",
    "\n",
    "    new_model.add(Dense(512, activation=\"relu\"))\n",
    "\n",
    "    # Add the final layer for the actual classification\n",
    "    new_model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def trainableLayers(model):\n",
    "    for i in range(len(list(model.layers))):\n",
    "        print(list(model.layers)[i].name)\n",
    "    return list(model.layers)[-1].name\n",
    "\n",
    "\n",
    "def history(model, generator_train, generator_val):\n",
    "    optimizer = Adam(lr=1e-5)\n",
    "    loss = \"categorical_crossentropy\"\n",
    "    metrics = [\"categorical_accuracy\"]\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    epochs = 25\n",
    "    steps_per_epoch = (generator_train.n / batch_size) / 3\n",
    "    steps_val = generator_val.n / batch_size\n",
    "    history = model.fit_generator(\n",
    "        generator=generator_train,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=generator_val,\n",
    "        validation_steps=steps_val,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "def plotmodel(model):\n",
    "    return tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        dpi=96,\n",
    "    )\n",
    "\n",
    "\n",
    "def plotGraph(h):\n",
    "    pd.DataFrame(h.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "HqBOAUC5h-DQ",
    "outputId": "94f6d4ee-9623-4f95-f0cf-efb394f43ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape=224,224\n",
    "datagen_train = ImageDataGenerator(rescale=1.0 / 255)\n",
    "datagen_test = ImageDataGenerator(rescale=1.0 / 255)\n",
    "datagen_val = ImageDataGenerator(rescale=1.0 / 255)\n",
    "batch_size = 16\n",
    "generator_train = datagen_train.flow_from_directory(\n",
    "    directory=train_dir, target_size=input_shape, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(\n",
    "    directory=test_dir, target_size=input_shape, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "generator_val = datagen_val.flow_from_directory(\n",
    "    directory=val_dir, target_size=input_shape, batch_size=batch_size, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xAI(model, img_dir):\n",
    "    image = Image.open(img_dir)\n",
    "    image = image.resize((224, 224))\n",
    "    img = np.asarray(image)\n",
    "    print(img.shape)\n",
    "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
    "    explanation = explainer.explain_instance(img, vgg16.predict)\n",
    "    image, mask = explanation.get_image_and_mask(\n",
    "        vgg16.predict(img.reshape((1, 224, 224, 3))).argmax(axis=1)[0],\n",
    "        positive_only=False,\n",
    "        hide_rest=False,\n",
    "    )\n",
    "    plt.imshow(mark_boundaries(image, mask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 14s 0us/step\n",
      "input_1\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_pool\n",
      "Last Layer : block5_pool\n"
     ]
    }
   ],
   "source": [
    "model1 = VGG16(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "l1 = trainableLayers(model1)\n",
    "print(\"Last Layer : \" + l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = model1.get_layer(l1)\n",
    "vgg16 = transferLayer(model1, layer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 27,561,282\n",
      "Trainable params: 27,561,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.optimizer_v2.adam.Adam object at 0x000001AB0A98CE50>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2576/3362434799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# For cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplotGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2576/2538388880.py\u001b[0m in \u001b[0;36mhistory\u001b[1;34m(model, generator_train, generator_val)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"categorical_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgenerator_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n\u001b[0;32m    572\u001b[0m           loss, loss_weights, output_names=self.output_names)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    606\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m       if (loss_scale is not None and\n\u001b[0;32m    601\u001b[0m           not isinstance(opt, lso.LossScaleOptimizer)):\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    132\u001b[0m         'Could not interpret optimizer identifier: {}'.format(identifier))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.optimizer_v2.adam.Adam object at 0x000001AB0A98CE50>"
     ]
    }
   ],
   "source": [
    "# For cross-validation\n",
    "h1 = history(vgg16, generator_train, generator_val)\n",
    "plotGraph(h1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Explanable AI on VGG16\n",
    "xAI(vgg16, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAI(vgg16, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAI(vgg16, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAI(vgg16, \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = ResNet50(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "l4 = trainableLayers(model4)\n",
    "print(\"Last Layer : \" + l4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer4 = model4.get_layer(l4)\n",
    "r50 = transferLayer(model4, layer4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cross-validation\n",
    "h4 = history(r50, generator_train, generator_val)\n",
    "plotGraph(h4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = InceptionV3(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "l3 = trainableLayers(model3)\n",
    "print(\"Last Layer : \" + l3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer3 = model3.get_layer(l3)\n",
    "iv3 = transferLayer(model3, layer3)\n",
    "# plotmodel(iv3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cross-validation\n",
    "h3 = history(iv3, generator_train, generator_val)\n",
    "plotGraph(h3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
